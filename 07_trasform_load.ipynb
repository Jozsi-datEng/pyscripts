{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 30)\n",
    "import requests\n",
    "%run \"00_common_res.ipynb\"\n",
    "# import os\n",
    "# %run func/df_to_csv.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "steps\n",
    "1. get data from S3\n",
    "2. wheater data transfommations\n",
    "3. taxi data transfommations\n",
    "4. update payment types table\n",
    "5. update companys table\n",
    "6. update taxi data with company and payment types ids (replace strings with id from latest tables)\n",
    "7-8. upload taxi and weather data to s3\n",
    "9. upload new company and payment types table to s3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 1 day trip data from protal by API\n",
    "url_chportal_taxi_api = (f\"https://data.cityofchicago.org/resource/ajtu-isnz.json?\"\n",
    "    f\"$where=trip_start_timestamp >= '{formatted_date}T00:00:00' \"\n",
    "    f\"AND trip_start_timestamp <= '{formatted_date}T23:59:59'&$limit=30000\")\n",
    "res_chportal_api = requests.get(url_chportal_taxi_api)\n",
    "# format to json\n",
    "js_taxi_data = res_chportal_api.json()\n",
    "# convert json format data to dataFrame\n",
    "df_taxi_data =  pd.DataFrame (js_taxi_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trasfomation part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### taxi data transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# typing help fir dict creation:-)\n",
    "df_col_types = df_taxi_data.dtypes\n",
    "for s_colname in df_col_types.keys():\n",
    "    print(f'\"{s_colname}\": \"{df_col_types[s_colname]}\",')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taxi_data_transformations(df_taxi_data):\n",
    "    \"\"\" taxi_data_transformations\n",
    "    ver: v1.1\n",
    "    Params:\n",
    "        df_taxi_data (df): original daly taxi data\n",
    "    Returns:\n",
    "        df: cleaned & trasform taxi data\n",
    "    requirements:\n",
    "        module(s): pandas\n",
    "    \"\"\"\n",
    "    # drop unnecessary columns\n",
    "    df_taxi_data.drop([\"pickup_census_tract\", \"dropoff_census_tract\"], axis=1, inplace=True)\n",
    "    df_taxi_data.drop([\"pickup_centroid_location\", \"dropoff_centroid_location\"], axis=1, inplace=True)\n",
    "\n",
    "    # drop rows that have missings\n",
    "    df_taxi_data.dropna (inplace=True)\n",
    "\n",
    "    # renaming cols\n",
    "    di_col_old_new = {\n",
    "        \"pickup_community_area\": \"pickup_community_area_id\", \"dropoff_community_area\": \"dropoff_community_area_id\"}\n",
    "    df_taxi_data.rename (columns=di_col_old_new, inplace=True)\n",
    "\n",
    "    # create helper column\n",
    "    df_taxi_data[\"datetime_for_weather\"] = pd.to_datetime(df_taxi_data[\"trip_start_timestamp\"])\n",
    "\n",
    "    # time rounding\n",
    "    df_taxi_data[\"datetime_for_weather\"] = df_taxi_data[\"datetime_for_weather\"].dt.floor(\"h\")\n",
    "\n",
    "    # create dict with types def\n",
    "    di_df_col_type = {\n",
    "        \"trip_id\": \"object\",\n",
    "        \"taxi_id\": \"object\",\n",
    "        \"trip_start_timestamp\": \"datetime64[ns]\",\n",
    "        \"trip_end_timestamp\": \"datetime64[ns]\",\n",
    "        \"trip_seconds\": \"int32\",\n",
    "        \"trip_miles\": \"float64\",\n",
    "        \"pickup_community_area_id\": \"int8\",\n",
    "        \"dropoff_community_area_id\": \"int8\",\n",
    "        \"fare\": \"float64\",\n",
    "        \"tips\": \"float64\",\n",
    "        \"tolls\": \"float64\",\n",
    "        \"extras\": \"float64\",\n",
    "        \"trip_total\": \"float64\",\n",
    "        \"payment_type\": \"object\",\n",
    "        \"company\": \"object\",\n",
    "        \"pickup_centroid_latitude\": \"object\",\n",
    "        \"pickup_centroid_longitude\": \"object\",\n",
    "        \"dropoff_centroid_latitude\": \"object\",\n",
    "        \"dropoff_centroid_longitude\": \"object\",\n",
    "        \"datetime_for_weather\": \"datetime64[ns]\"\n",
    "    }\n",
    "    # apply to dataFrame\n",
    "    df_taxi_data = df_taxi_data.astype(di_df_col_type)\n",
    "    return df_taxi_data\n",
    "\n",
    "taxi_data_transformations(df_taxi_data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### update master table function develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define column & dim table names to generate\n",
    "ls_dim_names = [\n",
    "        ['payment_type', 'df_payment_types_new'],\n",
    "        ['company', 'df_companys_new']\n",
    "    ]\n",
    "\n",
    "# craete dim tables\n",
    "for ls_dim_names_row in ls_dim_names:\n",
    "    # generate unique extracts\n",
    "    df_dim_tmp = df_taxi_data[ls_dim_names_row[0]].drop_duplicates()\n",
    "    df_dim_tmp = df_dim_tmp.sort_values(ignore_index=True)\n",
    "\n",
    "    # create dim table\n",
    "    df_dim_tmp = pd.DataFrame(\n",
    "        {\n",
    "            f'{ls_dim_names_row[0]}_id': range(1, len(df_dim_tmp)+1), # create range for ID\n",
    "            ls_dim_names_row[0]: df_dim_tmp\n",
    "\n",
    "        }\n",
    "    )\n",
    "    # rename dataFrame\n",
    "    globals()[ls_dim_names_row[1]] = df_dim_tmp\n",
    "\n",
    "    \n",
    "    ## save\n",
    "    # s_path_dim = s_path_sep.join([s_base_path, s_dir_data, ls_dim_names_row[1]+'.csv'])\n",
    "    # df_export_to_csv(df_dim_tmp, s_path_dim, s_dir_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat the end of master table, to simulate miss\n",
    "df_companys = df_companys_new.iloc[0:24]\n",
    "# make a new table that simulate actual dim status\n",
    "df_companys_new = df_companys_new.drop([0,1,2]).reset_index(drop=True)\n",
    "df_companys_new = df_companys_new.drop('company_id', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### master_table_add function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_table_add(df_master, df_dim, s_id_name, s_column_label):\n",
    "    \"\"\" compare master and dim table. Expand master with new items if necessary.\n",
    "    ver: 1.0\n",
    "    Params:\n",
    "        df_master (df): master data table\n",
    "        df_dim (df): Actual dim (extract) table from taxi data\n",
    "        s_id_name (str): master table id column name\n",
    "        s_column_label (str): master table label column name\n",
    "    Returns:\n",
    "        df: extended master table with new item(s)\n",
    "    requirements:\n",
    "        module(s): pandas\n",
    "    \"\"\"\n",
    "    s_my_name = 'master_table_add'\n",
    "    # we compare them with sets form\n",
    "    se_dim = set(df_dim[s_column_label].to_list())\n",
    "    se_master = set(df_master[s_column_label].to_list())\n",
    "    # make an additive list\n",
    "    ls_dim = list(se_dim - se_master)\n",
    "    # if there is'nt new element(s), return with original dataFrame\n",
    "    if not ls_dim:\n",
    "        print(f'Function {s_my_name}: No new element was added to the master table')\n",
    "        return df_master\n",
    "    # calc new id list\n",
    "    ls_master_id = list(range(len(df_master)+1,len(df_master) + len(ls_dim)+1))\n",
    "    # create a dict with the lists\n",
    "    di_company_add = {s_id_name: ls_master_id, s_column_label: ls_dim}\n",
    "    # put a dataFrame\n",
    "    df_add = pd.DataFrame(di_company_add)\n",
    "    # concat them\n",
    "    df_master = pd.concat([df_master, df_add], ignore_index=True)\n",
    "    print(f'Function {s_my_name}: master table was updated!')\n",
    "    return df_master\n",
    "\n",
    "df_companys = master_table_add(df_master=df_companys, df_dim=df_companys_new, s_id_name='company_id', s_column_label='company')\n",
    "df_companys\n",
    "\n",
    "# alternative comparison\n",
    "# pd.merge(df_companys_new, df_companys['company'], on= 'company', how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1).reset_index(drop=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
