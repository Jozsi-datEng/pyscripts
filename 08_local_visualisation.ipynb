{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "from my_s3_func import *\n",
    "from func.df_fix_str_cols_to_dtime_and_conv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my s3 global variables\n",
    "s_mybucket = \"jozsi-chicago-taxi-bb\"\n",
    "pathdir_proc_taxi = 'raw_data/to_process/taxi_data/'\n",
    "pathdir_processed_taxi = 'raw_data/processed/taxi_data/'\n",
    "pathdir_transf_taxi = 'transfomed_data/taxi_data/'\n",
    "pathdir_proc_wheater = 'raw_data/to_process/weather_data/'\n",
    "pathdir_processed_wheater = 'raw_data/processed/weather_data/'\n",
    "pathdir_transf_wheater = 'transfomed_data/weather_data/'\n",
    "pathdir_pay_type_master = 'transfomed_data/payment_type/'\n",
    "pathdir_company_master = 'transfomed_data/company/'\n",
    "pathdir_prev_masters = 'transfomed_data/master_table_previous_version/'\n",
    "pathdir_areas =  'transfomed_data/community_areas/'\n",
    "pathdir_date = 'transfomed_data/date/'\n",
    "\n",
    "s_pay_types = 'payment_types.csv'\n",
    "s_companies = 'companies.csv'\n",
    "s_taxi_data = 'taxi_data.csv'\n",
    "s_wheater_data = 'wheater_data.csv'\n",
    "s_areas = 'community_areas.csv'\n",
    "s_date = 'date.csv'\n",
    "\n",
    "s_aws_id = os.getenv('AWS_ACCESS_ID')\n",
    "s_aws_key = os.getenv('AWS_SEC_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "community_areas.csv has been loaded to df_community_areas\n",
      "companies.csv has been loaded to df_companies\n",
      "date.csv has been loaded to df_date\n",
      "payment_types.csv has been loaded to df_payment_types\n"
     ]
    }
   ],
   "source": [
    "# single files\n",
    "# def object list\n",
    "ls_path_file = [\n",
    "    [pathdir_areas,s_areas],\n",
    "    [pathdir_company_master, s_companies],\n",
    "    [pathdir_date, s_date],\n",
    "    [pathdir_pay_type_master, s_pay_types],\n",
    "    ]\n",
    "\n",
    "# get files from s3, a load to dynamic generate global dataframe variables\n",
    "for s_path, s_file in ls_path_file:\n",
    "    globals()['df_'+s_file.replace('.csv', '')] = load_s3_csv_to_df(s_bucket=s_mybucket, path_file=s_path+s_file, s_access_id=s_aws_id, s_sec_key=s_aws_key )\n",
    "    print(f'{s_file} has been loaded to df_{s_file.replace('.csv', '')}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taxi_data_2024-10-18.csv has loaded and added\n",
      "taxi_data_2024-10-19.csv has loaded and added\n",
      "taxi_data_2024-10-20.csv has loaded and added\n",
      "taxi_data_2024-10-21.csv has loaded and added\n",
      "taxi_data_2024-10-22.csv has loaded and added\n",
      "taxi_data_2024-10-23.csv has loaded and added\n",
      "taxi_data_2024-10-24.csv has loaded and added\n",
      "taxi_data_2024-10-25.csv has loaded and added\n",
      "taxi_data_2024-10-26.csv has loaded and added\n",
      "taxi_data_2024-10-27.csv has loaded and added\n",
      "taxi_data_2024-10-28.csv has loaded and added\n"
     ]
    }
   ],
   "source": [
    "# load & concat all taxi_data\n",
    "df_taxi_data_concat = load_s3_dir_csv_files(\n",
    "    s_bucket=s_mybucket, \n",
    "    path_work=pathdir_transf_taxi,  \n",
    "    s_access_id=s_aws_id, \n",
    "    s_sec_key=s_aws_key\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wheater_data_2024-10-18.csv has loaded and added\n",
      "wheater_data_2024-10-19.csv has loaded and added\n",
      "wheater_data_2024-10-20.csv has loaded and added\n",
      "wheater_data_2024-10-21.csv has loaded and added\n",
      "wheater_data_2024-10-22.csv has loaded and added\n",
      "wheater_data_2024-10-23.csv has loaded and added\n",
      "wheater_data_2024-10-24.csv has loaded and added\n",
      "wheater_data_2024-10-25.csv has loaded and added\n",
      "wheater_data_2024-10-26.csv has loaded and added\n",
      "wheater_data_2024-10-27.csv has loaded and added\n",
      "wheater_data_2024-10-28.csv has loaded and added\n"
     ]
    }
   ],
   "source": [
    "# load & concat all wheater_data\n",
    "df_wheather_data_concat = load_s3_dir_csv_files(\n",
    "    s_bucket=s_mybucket, \n",
    "    path_work=pathdir_transf_wheater,  \n",
    "    s_access_id=s_aws_id, \n",
    "    s_sec_key=s_aws_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enrichments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I always use a left join for this step to avoid losing data from the main table due to a join error\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_concat, df_community_areas, left_on='pickup_community_area_id', right_on='area code', how='left')\n",
    "df_taxi_data_full.rename(columns={'community name': 'pickup_area_name'}, inplace=True)\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_community_areas, left_on='dropoff_community_area_id', right_on='area code', how='left')\n",
    "df_taxi_data_full.rename(columns={'community name': 'dropof_area_name'}, inplace=True)\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_payment_types, on='payment_type_id', how='left')\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_companies, on='company_id', how='left')\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_wheather_data_concat, left_on='datetime_for_weather', right_on='datetime', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation and join df_date\n",
    "# fix values (if possible) and convert cols type to datatime\n",
    "s_columns = ['trip_start_timestamp', 'trip_end_timestamp']\n",
    "df_fix_str_cols_to_dtime_and_conv(df_taxi_data_full, s_columns)\n",
    "# make a new \"date\" col for join\n",
    "df_taxi_data_full['trip_start_date'] = df_taxi_data_full['trip_start_timestamp'].dt.date.astype(str)\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_date, left_on='trip_start_date', right_on='Date', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "df_taxi_data_full = df_taxi_data_full.drop(columns=['area code_x','area code_y', 'datetime', 'Date'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' \n",
    "# 1. Which 10 companies make the most money?\n",
    "# Use two columns: Company name and the sum of the fare. Order by descending order.\n",
    "# Make sure that the sum of the fares (total_fare) is not in scientific notation.\n",
    "# '''\n",
    "\n",
    "# pd.options.display.float_format = lambda x: '{:,.0f}'.format(x).replace(',', ' ')\n",
    "\n",
    "# query = '''\n",
    "# SELECT \n",
    "# \tcompany, \n",
    "#     ROUND(SUM(trip_total),0) AS trips_total_usd\n",
    "# FROM df_taxi_data_full\n",
    "# GROUP BY company_id\n",
    "# ORDER BY trips_total_usd DESC\n",
    "# LIMIT 10\n",
    "# '''\n",
    "# df_res = ps.sqldf(query, locals())\n",
    "# df_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189782 entries, 0 to 189781\n",
      "Data columns (total 34 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   trip_id                     189782 non-null  object        \n",
      " 1   taxi_id                     189782 non-null  object        \n",
      " 2   trip_start_timestamp        189782 non-null  datetime64[ns]\n",
      " 3   trip_end_timestamp          189782 non-null  datetime64[ns]\n",
      " 4   trip_seconds                189782 non-null  int64         \n",
      " 5   trip_miles                  189782 non-null  float64       \n",
      " 6   pickup_community_area_id    189782 non-null  int64         \n",
      " 7   fare                        189782 non-null  float64       \n",
      " 8   tips                        189782 non-null  float64       \n",
      " 9   tolls                       189782 non-null  float64       \n",
      " 10  extras                      189782 non-null  float64       \n",
      " 11  trip_total                  189782 non-null  float64       \n",
      " 12  pickup_centroid_latitude    189782 non-null  float64       \n",
      " 13  pickup_centroid_longitude   189782 non-null  float64       \n",
      " 14  dropoff_community_area_id   189782 non-null  int64         \n",
      " 15  dropoff_centroid_latitude   189782 non-null  float64       \n",
      " 16  dropoff_centroid_longitude  189782 non-null  float64       \n",
      " 17  datetime_for_weather        189782 non-null  object        \n",
      " 18  payment_type_id             189782 non-null  int64         \n",
      " 19  company_id                  189782 non-null  int64         \n",
      " 20  pickup_area_name            189782 non-null  object        \n",
      " 21  dropof_area_name            189782 non-null  object        \n",
      " 22  payment_type                189782 non-null  object        \n",
      " 23  company                     189782 non-null  object        \n",
      " 24  tempretaure                 189697 non-null  float64       \n",
      " 25  wind_speed                  189697 non-null  float64       \n",
      " 26  rain                        189697 non-null  float64       \n",
      " 27  precipitation               189697 non-null  float64       \n",
      " 28  trip_start_date             189782 non-null  object        \n",
      " 29  year                        189782 non-null  int64         \n",
      " 30  month                       189782 non-null  int64         \n",
      " 31  day                         189782 non-null  int64         \n",
      " 32  day_of_week                 189782 non-null  int64         \n",
      " 33  is_weekend                  189782 non-null  bool          \n",
      "dtypes: bool(1), datetime64[ns](2), float64(14), int64(9), object(8)\n",
      "memory usage: 48.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# df_taxi_data_full.describe(include='all')\n",
    "df_taxi_data_full.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 2. Show the 10 pickup community areas with the most rides.\n",
    "# Use two columns: community area name and count of rides per area, in descending order for\n",
    "# the rides.\n",
    "# '''\n",
    "\n",
    "# query = '''\n",
    "# SELECT \n",
    "#     pickup_area_name,\n",
    "#     COUNT(*) AS rides_count\n",
    "# FROM df_taxi_data_full\n",
    "# GROUP BY pickup_community_area_id\n",
    "# ORDER BY rides_count DESC\n",
    "# LIMIT 10\n",
    "# '''\n",
    "# df_res = ps.sqldf(query, locals())\n",
    "# df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 3. Get the count of taxi rides per day of week. In other words, we'd like to see which day has\n",
    "# the most rides.\n",
    "# Use the names of the days instead of numbers (Monday = 1, Tuesday = 2, etc.).\n",
    "# HINT: Check CASE WHEN statements for replacing names of days. For ordering the results by\n",
    "# the day you can use MIN(day_of_the_week).\n",
    "# '''\n",
    "\n",
    "# query = '''\n",
    "# SELECT \n",
    "#     CASE \n",
    "#         WHEN day_of_week = '1' THEN 'Monday'\n",
    "#         WHEN day_of_week = '2' THEN 'Tuesday'\n",
    "#         WHEN day_of_week = '3' THEN 'Wednesday'\n",
    "#         WHEN day_of_week = '4' THEN 'Thursday'\n",
    "#         WHEN day_of_week = '5' THEN 'Friday'\n",
    "#         WHEN day_of_week = '6' THEN 'Saturday'\n",
    "#         WHEN day_of_week = '7' THEN 'Sunday'\n",
    "#         ELSE 'wrong data'\n",
    "#     END AS day_of_week,\n",
    "#     COUNT(*) AS rides_count\n",
    "# FROM df_taxi_data_full\n",
    "# GROUP BY day_of_week\n",
    "# ORDER BY rides_count DESC\n",
    "# '''\n",
    "# df_res = ps.sqldf(query, locals())\n",
    "# df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 189782 entries, 0 to 189781\n",
      "Data columns (total 34 columns):\n",
      " #   Column                      Non-Null Count   Dtype         \n",
      "---  ------                      --------------   -----         \n",
      " 0   trip_id                     189782 non-null  object        \n",
      " 1   taxi_id                     189782 non-null  object        \n",
      " 2   trip_start_timestamp        189782 non-null  datetime64[ns]\n",
      " 3   trip_end_timestamp          189782 non-null  datetime64[ns]\n",
      " 4   trip_seconds                189782 non-null  int64         \n",
      " 5   trip_miles                  189782 non-null  float64       \n",
      " 6   pickup_community_area_id    189782 non-null  int64         \n",
      " 7   fare                        189782 non-null  float64       \n",
      " 8   tips                        189782 non-null  float64       \n",
      " 9   tolls                       189782 non-null  float64       \n",
      " 10  extras                      189782 non-null  float64       \n",
      " 11  trip_total                  189782 non-null  float64       \n",
      " 12  pickup_centroid_latitude    189782 non-null  float64       \n",
      " 13  pickup_centroid_longitude   189782 non-null  float64       \n",
      " 14  dropoff_community_area_id   189782 non-null  int64         \n",
      " 15  dropoff_centroid_latitude   189782 non-null  float64       \n",
      " 16  dropoff_centroid_longitude  189782 non-null  float64       \n",
      " 17  datetime_for_weather        189782 non-null  object        \n",
      " 18  payment_type_id             189782 non-null  int64         \n",
      " 19  company_id                  189782 non-null  int64         \n",
      " 20  pickup_area_name            189782 non-null  object        \n",
      " 21  dropof_area_name            189782 non-null  object        \n",
      " 22  payment_type                189782 non-null  object        \n",
      " 23  company                     189782 non-null  object        \n",
      " 24  tempretaure                 189697 non-null  float64       \n",
      " 25  wind_speed                  189697 non-null  float64       \n",
      " 26  rain                        189697 non-null  float64       \n",
      " 27  precipitation               189697 non-null  float64       \n",
      " 28  trip_start_date             189782 non-null  object        \n",
      " 29  year                        189782 non-null  int64         \n",
      " 30  month                       189782 non-null  int64         \n",
      " 31  day                         189782 non-null  int64         \n",
      " 32  day_of_week                 189782 non-null  int64         \n",
      " 33  is_weekend                  189782 non-null  bool          \n",
      "dtypes: bool(1), datetime64[ns](2), float64(14), int64(9), object(8)\n",
      "memory usage: 48.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# df_taxi_data_full.describe(include='all')\n",
    "df_taxi_data_full.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_data = df_taxi_data_full\n",
    "\n",
    "# error detection function\n",
    "def detect_errors(row):\n",
    "    errors = []\n",
    "    \n",
    "    # missing data\n",
    "    if row.isnull().any():\n",
    "        errors.append('missing_data')\n",
    "    \n",
    "    # trip distance = 0, but the pickup and dropoff coordinates are diferent\n",
    "    if (row['trip_miles'] == 0.0\n",
    "        and (\n",
    "            row['pickup_centroid_latitude'] != row['dropoff_centroid_latitude']\n",
    "            or row['pickup_centroid_longitude'] != row['dropoff_centroid_longitude']\n",
    "            )\n",
    "        ):\n",
    "        errors.append('distance')\n",
    "    \n",
    "    # trip time the calculated trip time are differ significantly\n",
    "    timestamp_diff = abs(row['trip_end_timestamp'] - row['trip_start_timestamp']).seconds\n",
    "    if ( timestamp_diff - row['trip_seconds'] >= 900 ): # max 15 minutes granulation difference\n",
    "        errors.append('trip_time')\n",
    "    \n",
    "    return errors\n",
    "\n",
    "# new column for the error types\n",
    "df_data['anomaly_types'] = df_data.apply(detect_errors, axis=1)\n",
    "\n",
    "# convert the list of error types to a string\n",
    "df_data['anomaly_types'] = df_data['anomaly_types'].apply(lambda x: x if x else None)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
