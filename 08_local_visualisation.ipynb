{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandasql as ps\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from my_s3_func import *\n",
    "from func.df_fix_str_cols_to_dtime_and_conv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my s3 global variables\n",
    "s_mybucket = \"jozsi-chicago-taxi-bb\"\n",
    "pathdir_proc_taxi = 'raw_data/to_process/taxi_data/'\n",
    "pathdir_processed_taxi = 'raw_data/processed/taxi_data/'\n",
    "pathdir_transf_taxi = 'transfomed_data/taxi_data/'\n",
    "pathdir_proc_wheater = 'raw_data/to_process/weather_data/'\n",
    "pathdir_processed_wheater = 'raw_data/processed/weather_data/'\n",
    "pathdir_transf_wheater = 'transfomed_data/weather_data/'\n",
    "pathdir_pay_type_master = 'transfomed_data/payment_type/'\n",
    "pathdir_company_master = 'transfomed_data/company/'\n",
    "pathdir_prev_masters = 'transfomed_data/master_table_previous_version/'\n",
    "pathdir_areas =  'transfomed_data/community_areas/'\n",
    "pathdir_date = 'transfomed_data/date/'\n",
    "\n",
    "s_pay_types = 'payment_types.csv'\n",
    "s_companies = 'companies.csv'\n",
    "s_taxi_data = 'taxi_data.csv'\n",
    "s_wheater_data = 'wheater_data.csv'\n",
    "s_areas = 'community_areas.csv'\n",
    "s_date = 'date.csv'\n",
    "\n",
    "s_aws_id = os.getenv('AWS_ACCESS_ID')\n",
    "s_aws_key = os.getenv('AWS_SEC_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get data from s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single files\n",
    "# def object list\n",
    "ls_path_file = [\n",
    "    [pathdir_areas,s_areas],\n",
    "    [pathdir_company_master, s_companies],\n",
    "    [pathdir_date, s_date],\n",
    "    [pathdir_pay_type_master, s_pay_types],\n",
    "    ]\n",
    "\n",
    "# get files from s3, a load to dynamic generate global dataframe variables\n",
    "for s_path, s_file in ls_path_file:\n",
    "    globals()['df_'+s_file.replace('.csv', '')] = load_s3_csv_to_df(s_bucket=s_mybucket, path_file=s_path+s_file, s_access_id=s_aws_id, s_sec_key=s_aws_key )\n",
    "    print(f'{s_file} has been loaded to df_{s_file.replace('.csv', '')}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & concat all taxi_data\n",
    "df_taxi_data_concat = load_s3_dir_csv_files(\n",
    "    s_bucket=s_mybucket, \n",
    "    path_work=pathdir_transf_taxi,  \n",
    "    s_access_id=s_aws_id, \n",
    "    s_sec_key=s_aws_key\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load & concat all wheater_data\n",
    "df_wheather_data_concat = load_s3_dir_csv_files(\n",
    "    s_bucket=s_mybucket, \n",
    "    path_work=pathdir_transf_wheater,  \n",
    "    s_access_id=s_aws_id, \n",
    "    s_sec_key=s_aws_key\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enrichments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I always use a left join for this step to avoid losing data from the main table due to a join error\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_concat, df_community_areas, left_on='pickup_community_area_id', right_on='area code', how='left')\n",
    "df_taxi_data_full.rename(columns={'community name': 'pickup_area_name'}, inplace=True)\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_community_areas, left_on='dropoff_community_area_id', right_on='area code', how='left')\n",
    "df_taxi_data_full.rename(columns={'community name': 'dropof_area_name'}, inplace=True)\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_payment_types, on='payment_type_id', how='left')\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_companies, on='company_id', how='left')\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_wheather_data_concat, left_on='datetime_for_weather', right_on='datetime', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation and join df_date\n",
    "# fix values (if possible) and convert cols type to datatime\n",
    "s_columns = ['trip_start_timestamp', 'trip_end_timestamp']\n",
    "df_fix_str_cols_to_dtime_and_conv(df_taxi_data_full, s_columns)\n",
    "# make a new \"date\" col for join\n",
    "df_taxi_data_full['trip_start_date'] = df_taxi_data_full['trip_start_timestamp'].dt.date.astype(str)\n",
    "df_taxi_data_full = pd.merge(df_taxi_data_full, df_date, left_on='trip_start_date', right_on='Date', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns\n",
    "df_taxi_data_full = df_taxi_data_full.drop(columns=['area code_x','area code_y', 'datetime', 'Date'], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' \n",
    "# 1. Which 10 companies make the most money?\n",
    "# Use two columns: Company name and the sum of the fare. Order by descending order.\n",
    "# Make sure that the sum of the fares (total_fare) is not in scientific notation.\n",
    "# '''\n",
    "\n",
    "# pd.options.display.float_format = lambda x: '{:,.0f}'.format(x).replace(',', ' ')\n",
    "\n",
    "# query = '''\n",
    "# SELECT \n",
    "# \tcompany, \n",
    "#     ROUND(SUM(trip_total),0) AS trips_total_usd\n",
    "# FROM df_taxi_data_full\n",
    "# GROUP BY company_id\n",
    "# ORDER BY trips_total_usd DESC\n",
    "# LIMIT 10\n",
    "# '''\n",
    "# df_res = ps.sqldf(query, locals())\n",
    "# df_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 2. Show the 10 pickup community areas with the most rides.\n",
    "# Use two columns: community area name and count of rides per area, in descending order for\n",
    "# the rides.\n",
    "# '''\n",
    "\n",
    "# query = '''\n",
    "# SELECT \n",
    "#     pickup_area_name,\n",
    "#     COUNT(*) AS rides_count\n",
    "# FROM df_taxi_data_full\n",
    "# GROUP BY pickup_community_area_id\n",
    "# ORDER BY rides_count DESC\n",
    "# LIMIT 10\n",
    "# '''\n",
    "# df_res = ps.sqldf(query, locals())\n",
    "# df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# 3. Get the count of taxi rides per day of week. In other words, we'd like to see which day has\n",
    "# the most rides.\n",
    "# Use the names of the days instead of numbers (Monday = 1, Tuesday = 2, etc.).\n",
    "# HINT: Check CASE WHEN statements for replacing names of days. For ordering the results by\n",
    "# the day you can use MIN(day_of_the_week).\n",
    "# '''\n",
    "\n",
    "# query = '''\n",
    "# SELECT \n",
    "#     CASE \n",
    "#         WHEN day_of_week = '1' THEN 'Monday'\n",
    "#         WHEN day_of_week = '2' THEN 'Tuesday'\n",
    "#         WHEN day_of_week = '3' THEN 'Wednesday'\n",
    "#         WHEN day_of_week = '4' THEN 'Thursday'\n",
    "#         WHEN day_of_week = '5' THEN 'Friday'\n",
    "#         WHEN day_of_week = '6' THEN 'Saturday'\n",
    "#         WHEN day_of_week = '7' THEN 'Sunday'\n",
    "#         ELSE 'wrong data'\n",
    "#     END AS day_of_week,\n",
    "#     COUNT(*) AS rides_count\n",
    "# FROM df_taxi_data_full\n",
    "# GROUP BY day_of_week\n",
    "# ORDER BY rides_count DESC\n",
    "# '''\n",
    "# df_res = ps.sqldf(query, locals())\n",
    "# df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dirty, anomality cheks and notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_taxi_vis = df_taxi_data_full\n",
    "\n",
    "# error detection function\n",
    "def detect_errors(row):\n",
    "    errors = []\n",
    "    \n",
    "    # missing data\n",
    "    if row.isnull().any():\n",
    "        errors.append('missing_data')\n",
    "    \n",
    "    # trip distance = 0, but the pickup and dropoff coordinates are diferent\n",
    "    if(\n",
    "        row['trip_miles'] == 0.0\n",
    "        and (\n",
    "            row['pickup_centroid_latitude'] != row['dropoff_centroid_latitude']\n",
    "            or row['pickup_centroid_longitude'] != row['dropoff_centroid_longitude']\n",
    "            )\n",
    "        ):\n",
    "        errors.append('is_movement')\n",
    "    \n",
    "    # trip time the calculated trip time are differ significantly\n",
    "    timestamp_diff = abs(row['trip_end_timestamp'] - row['trip_start_timestamp']).seconds\n",
    "    if(\n",
    "        timestamp_diff - row['trip_seconds'] >= 900 \n",
    "        ): # max 15 minutes granulation difference\n",
    "        errors.append('trip_time')\n",
    "    \n",
    "    # was there a real fee payment?\n",
    "    if(\n",
    "        row['payment_type_id'] in [3,5,7] # 3: no charge, 4: dispute, 6: unknown (row['trip_total'] > 0.0 and )\n",
    "        ):\n",
    "        errors.append('is_payment')\n",
    "\n",
    "    # there was'nt real trip, but there was fee payment\n",
    "    if(\n",
    "        row['trip_miles'] == 0.0\n",
    "        and row['trip_total'] > 0.0\n",
    "        ):\n",
    "        errors.append('is_real_trip')\n",
    "    \n",
    "    return errors\n",
    "\n",
    "# new column for the error types\n",
    "df_taxi_vis['anomaly_types'] = df_taxi_vis.apply(detect_errors, axis=1)\n",
    "\n",
    "# apply the error types to the dataframe\n",
    "df_taxi_vis['anomaly_types'] = df_taxi_vis['anomaly_types'].apply(lambda x: x if x else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualizations with diagrams and graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude rows with anomalies for further analysis\n",
    "df_taxi_vis_clean = df_taxi_vis[df_taxi_vis['anomaly_types'].isnull()]\n",
    "# Date period\n",
    "start_date = df_taxi_vis_clean['trip_start_timestamp'].min().strftime('%Y-%m-%d')\n",
    "end_date = df_taxi_vis_clean['trip_end_timestamp'].max().strftime('%Y-%m-%d')\n",
    "s_period = f'Period: {start_date} - {end_date}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anomaly types by taxi companies\n",
    "df_anomaly_counts = df_taxi_vis.explode('anomaly_types').groupby(['anomaly_types', 'company']).size().reset_index(name='count')\n",
    "df_anomaly_counts = (\n",
    "    df_anomaly_counts.groupby('anomaly_types', group_keys=False)\n",
    "    .apply(lambda x: x.nlargest(5, 'count'))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(data=df_anomaly_counts, x='anomaly_types', y='count', hue='company', width=0.6)\n",
    "plt.title('Top 5 dirty data types by taxi companies - ' + s_period)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxi companies with the highest revenue\n",
    "df_taxi_revenue_top = df_taxi_vis_clean.groupby('company')['trip_total'].sum().nlargest(10).reset_index()\n",
    "# total revenue\n",
    "total_revenue = df_taxi_vis_clean['trip_total'].sum()\n",
    "# percentage of total revenue\n",
    "df_taxi_revenue_top['percentage'] = (df_taxi_revenue_top['trip_total'] / total_revenue) * 100\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(df_taxi_revenue_top['company'], df_taxi_revenue_top['percentage'], width=0.3)\n",
    "plt.title('Taxi companies with the highest revenue rate\\n' + s_period)\n",
    "plt.xticks(rotation=55)\n",
    "plt.ylabel('Percentage of total revenue')\n",
    "plt.xlabel('Taxi companies')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# payment types distribution\n",
    "df_payment_counts = df_taxi_vis_clean.groupby(['payment_type']).size().reset_index(name='count')\n",
    "sum_payment_counts = df_payment_counts['count'].sum()\n",
    "df_payment_counts['percentage'] = (df_payment_counts['count'] / sum_payment_counts * 100).round().astype(str) + '%'\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.title('Payment types distribution - ' + s_period)\n",
    "plt.pie(df_payment_counts['count'], labels = df_payment_counts['percentage'])\n",
    "plt.legend(df_payment_counts['payment_type'], title='Payment types', loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taxi trips by hour\n",
    "df_taxi_vis_clean = df_taxi_vis_clean.copy()\n",
    "df_taxi_vis_clean['hour'] = df_taxi_vis_clean['trip_start_timestamp'].dt.hour\n",
    "df_hourly_rides = df_taxi_vis_clean.groupby(['hour']).size().reset_index(name='count')\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(df_hourly_rides['hour'], df_hourly_rides['count'])\n",
    "plt.title('Taxi trip starts by hour - ' + s_period)\n",
    "plt.ylabel('Trip counts', fontsize=14)\n",
    "plt.xlabel('Hours', fontsize=14, labelpad=20)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# taxi trips by day\n",
    "df_daily_trip_cou = df_taxi_vis_clean.groupby(['trip_start_date']).size().reset_index(name='count')\n",
    "df_daily_trip_cou['date_weak_day'] = df_daily_trip_cou['trip_start_date'] + ' - ' + pd.to_datetime(df_daily_trip_cou['trip_start_date']).dt.day_name()\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.bar(df_daily_trip_cou['date_weak_day'], df_daily_trip_cou['count'], width=0.5)\n",
    "plt.title('Taxi trip starts by hour - ' + s_period)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Trip counts', fontsize=14)\n",
    "plt.xlabel('Start date and day', fontsize=14, labelpad=20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
